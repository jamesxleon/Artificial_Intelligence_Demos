{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search strategies implementation in Python and logic programming in Prolog\n",
    "## Part I: The status of chess as a topic in artificial intelligence\n",
    "### 1. Deep Blue\n",
    "A milestone in the research of chess was made by Feng-Hsiung Hsu and his team back in 1997 when Deep Blue, their specialized computer, beat the then world champion Garry Kasparov. In order to achieve this, important study was done on graph expansion and decision making techniques. Both related to the area of search. The highlights include, but are not limited to, the following:\n",
    "- When the machine beat Garry Kasparov, it searched about 200 million chess positions per second, using 480 custom chess chips, with each chip searching up to 3 million positions per second. \n",
    "- Ad hoc handwritten techniques for selective pruning were surpassed in performance by simple-minded brute force search subject to normal alpha-beta pruning. \n",
    "- Selective extensions emerged as an alternative to selective prunning. Which spent _less time searching the unpromising moves_ by just searching \"interesting\" lines deeper _without completely discarding them_. \n",
    "- Feng-Hsiung Hsu introduced the idea of _singular extensions_ in 1986 which used _test searches_ to perform searches not necessarily needed for regular search but useful to measure the forcefulness of the moves. Then, for example, if test searches suggest only one single \"good\" move is possible, then the \"good\" move deserves to be searched deeper.\n",
    "- A form of test search is _null move pruning_ where the test searches have one player making two moves in a row, with the opponent thus making a null movement in between. If the result is \"unsatisfactory\", then the first move by the player is unpromising and can be pruned away.\n",
    "- After chess was solved–i.e. a program was good enough to beat a world champion— harder games like the Japanese Shogi and the Chinese Go were suggested as next targets and 10 years solved by the use of neural networks by Deep Mind's AlphaGo.\n",
    "- AlphaGo used two deep neural networks: one for evaluation and the other for deciding which move to include in the search.\n",
    "- Deep Neural Networks serve as a proof that small improvements in a few areas, amplified by greater computation power, create huge differences.<br><br>\n",
    "\n",
    "*Source:* Hsu, F. (2022). Behind Deep Blue: Building the Computer That Defeated the World Chess Champion. Princeton University Press.\n",
    "\n",
    "### 2. Why bother improving search? The state-space complexity of chess\n",
    "Chess is a game of immense complexity, with a vast number of possible game states and moves. The state-space complexity of chess is estimated to be around 10^46.25. This is the number of legal chess positions, a number so large that it's impossible to compute all of them. The game-tree complexity, which is the total number of possible games, is even more astronomical, estimated to be around 10^123. This is more than the number of atoms in the observable universe!\n",
    "\n",
    "The complexity of chess makes it a perfect testbed for search algorithms. The goal of these algorithms is to navigate through this vast search space and find the best move in any given position. The better the search algorithm, the stronger the chess-playing AI can be. However, the brute force approach, which involves searching through all possible moves, is not feasible due to the game's complexity. Therefore, search strategies in chess AI focus on pruning the search tree and focusing on the most promising moves.\n",
    "\n",
    "The minimax algorithm, for instance, is a recursive algorithm used for decision making in game theory and artificial intelligence that simulates all possible games to determine the best move, assuming that the opponent is also playing optimally. To improve the efficiency of the minimax algorithm, alpha-beta pruning is often used. This technique eliminates branches in the game tree that do not need to be explored because there already exists a better move available.\n",
    "\n",
    "Another significant algorithm in chess AI is the Monte Carlo Tree Search (MCTS). This algorithm uses random sampling as part of the decision-making process. Unlike the minimax algorithm, MCTS does not need to evaluate all possible games. Instead, it uses statistical analysis of sample games to determine the best move. This makes MCTS particularly effective in complex game scenarios where the total number of possible games is too large to compute.\n",
    "\n",
    "Despite the complexity, chess has been effectively \"solved\" by AI, with programs like Deep Blue and AlphaZero able to beat world champion human players. This success has led to AI researchers moving on to even more complex games like Go and Shogi.\n",
    "\n",
    "*Sources:*<br>\n",
    "\n",
    "[MIT](http://web.mit.edu/6.034/wwwbob/GamesSolved.pdf) <br>\n",
    "\n",
    "[Scientific American](https://www.scientificamerican.com/article/20-years-after-deep-blue-how-ai-has-advanced-since-conquering-chess/)<br>\n",
    "\n",
    "[Chess Programming](https://www.chessprogramming.org/Shirish_Chinchalkar#cite_note-4)<br>\n",
    "\n",
    "[Core](https://core.ac.uk/download/pdf/81113423.pdf)<br>\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Solving_chess)<br>\n",
    "\n",
    "[Highlights in Science, Engineering and Technology - Tree Search Algorithms For Chinese Chess](https://drpress.org/ojs/index.php/HSET/article/view/1358)\n",
    "\n",
    "### 3. Chess byproducts: endgame tablebases\n",
    "Endgame tablebases are a significant byproduct of chess research and have been instrumental in solving complex endgame scenarios. They are essentially databases that contain the exact evaluation of all possible positions with a limited number of pieces on the board. The use of endgame tablebases has revolutionized the way chess endgames are studied and played, providing definitive answers to positions that were once considered too complex to analyze.\n",
    "\n",
    "The development of 8-piece endgame tablebases has been a significant milestone in this area. These tablebases contain all possible positions with eight pieces on the board, including the kings. The creation of these tablebases was a massive computational task, requiring the analysis of trillions of positions. The results have been fascinating, revealing new theoretical wins and drawing lines in positions that were previously thought to be decided.\n",
    "\n",
    "One of the most intriguing findings from the 8-piece endgame tablebases is the discovery of positions that require more than 500 moves to convert an advantage into a win. These positions, which are far beyond the 50-move rule applied in practical play, provide fascinating insights into the depth and complexity of chess.\n",
    "\n",
    "The use of endgame tablebases extends beyond pure theoretical interest. They are used in practical play by top chess engines to play the endgame perfectly. They also serve as a valuable tool for chess players and researchers to study and understand the endgame better.\n",
    "\n",
    "The creation of endgame tablebases is an ongoing process, with researchers continually working on larger tablebases. As the tablebases grow, they continue to reveal the immense complexity and beauty of chess, providing new insights and challenges for players and researchers.\n",
    "\n",
    "*Sources:*<br>\n",
    "\n",
    "[Chessbase - 8-piece endgame tablebases: first findings and interview](https://en.chessbase.com/post/8-piece-endgame-tablebases-first-findings-and-interview)<br>\n",
    "\n",
    "[Chessbase - Cooks and finds with 8-piece tablebases](https://en.chessbase.com/post/cooks-and-finds-with-8-piece-tablebases)<br>\n",
    "\n",
    "[Chessbase - Study of the month: Endgame studies, endgame theory](https://en.chessbase.com/post/study-of-the-month-endgame-studies-endgame-theory)<br>\n",
    "\n",
    "### 4. Beyond Chess: The Evolution of Game AI\n",
    "The success of AI in chess has paved the way for its application in other games and even beyond the realm of games. From classic board games like Go and Shogi to modern video games like StarCraft and Dota 2, AI has made significant strides. The complexity and diversity of these games provide new challenges and opportunities for AI research.\n",
    "\n",
    "In these games, AI has to deal with more complex state spaces, real-time decision-making, and multi-agent environments. For instance, in StarCraft, an AI player needs to manage resources, control multiple units simultaneously, and adapt to the strategies of the opponent. These tasks require advanced AI techniques such as deep reinforcement learning and multi-agent learning.\n",
    "\n",
    "Moreover, the advances in Game AI are not confined to games. They are being extended to other areas such as robotics and chemical synthesis. For example, the techniques used to solve the Rubik's cube with a robot hand are similar to those used in Game AI.\n",
    "\n",
    "The evolution of Game AI also highlights the importance of improving search strategies. As games become more complex, the search space becomes larger and more challenging to navigate. Therefore, developing more efficient and effective search algorithms remains a crucial task in AI research.\n",
    "\n",
    "*Source:* [Springer](https://link.springer.com/article/10.1007/s13218-020-00647-w)\n",
    "\n",
    "## Part II: Search strategies implemented in python for the 8-Tile puzzle (snippets from the code)\n",
    "### General Purpose Code\n",
    "The following functions are kept identical in BFS and DFS implementations. Both are in charge of \"moving the tiles\", i.e. changing the state of the board. For the A* search, a change is necessary only in the search function, as the apply_action() remains the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define the search function\n",
    "def search(state):\n",
    "    frontier.put(state)\n",
    "    G.add_node(state)\n",
    "    while not frontier.empty():\n",
    "        state = frontier.get()\n",
    "        if state == GOAL_STATE:\n",
    "            return True\n",
    "        for action in ACTIONS:\n",
    "            new_state = apply_action(state, action)\n",
    "            if new_state is not None and new_state not in G:\n",
    "                G.add_edge(state, new_state)\n",
    "                frontier.put(new_state)\n",
    "    return False\n",
    "\n",
    "# Define the action function\n",
    "def apply_action(state, action):\n",
    "    new_state = [list(row) for row in state]\n",
    "    i, j = next((i, j) for i, row in enumerate(state) for j, cell in enumerate(row) if cell == 0)\n",
    "    if action == 'up' and i > 0:\n",
    "        new_state[i][j], new_state[i - 1][j] = new_state[i - 1][j], new_state[i][j]\n",
    "    elif action == 'down' and i < 2:\n",
    "        new_state[i][j], new_state[i + 1][j] = new_state[i + 1][j], new_state[i][j]\n",
    "    elif action == 'left' and j > 0:\n",
    "        new_state[i][j], new_state[i][j - 1] = new_state[i][j - 1], new_state[i][j]\n",
    "    elif action == 'right' and j < 2:\n",
    "        new_state[i][j], new_state[i][j + 1] = new_state[i][j + 1], new_state[i][j]\n",
    "    else:\n",
    "        return None\n",
    "    return tuple(map(tuple, new_state))\n",
    "\n",
    "ACTIONS = ['up', 'down', 'left', 'right']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. BFS and DFS\n",
    "The most important consideration resulting from this implementation is to understand that the difference between a BFS and DFS lies on the data structure used to keep track of new_states. For BFS, a queue is used to force the search go through all the nodes by 'width'. On the other hand, DFS uses a stack to go through the nodes by 'height'. It is important to note that a deque is an equivalent to a stack in python. Both part of the _collections_ library of python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a queue for the frontier\n",
    "frontier = Queue()\n",
    "\n",
    "# Create a stack for the frontier\n",
    "frontier = deque()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A* Search\n",
    "\n",
    "The task here was to implement three heuristics for the evaluation function.  To achieve so, let's first define the search in terms of a cost associated to a candidate solution. Let's also note that the right data structure for this task is the Priority_queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Define the search function for A* search \n",
    "def search(state, g, heuristic):\n",
    "    # If the state is the goal state, return the cost\n",
    "    if state == GOAL_STATE:\n",
    "        return g\n",
    "\n",
    "    # Generate the state space\n",
    "    for action in ACTIONS:\n",
    "        new_state = apply_action(state, action)\n",
    "        if new_state is not None and new_state not in G:\n",
    "            G.add_edge(state, new_state)\n",
    "            cost = g + 1 + heuristic(new_state)\n",
    "            frontier.put((cost, new_state, g + 1))\n",
    "\n",
    "    # Continue the search\n",
    "    while not frontier.empty():\n",
    "        _, state, g = frontier.get()\n",
    "        cost = search(state, g, heuristic)\n",
    "        if cost is not None:\n",
    "            return cost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an extra consideration, the heuristic received as a parameter of the search function will be the responsible of determining the priority associated to an element added to the priority queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a priority queue for the frontier\n",
    "    frontier = PriorityQueue()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as the cost is calculated in function of a heuristic(), the heuristic can be defined separately to then assign it to the function. The assignation is achieved inside a loop which initializes all important variables (this way avoiding memory mismanagement) and then calling to the locally defined switch function to obtain a heuristic and pass it as an argument to the search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#...more code\n",
    "\n",
    "def Manhattan_heuristic(state):\n",
    "    distance = 0\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if state[i][j] != 0:\n",
    "                x, y = GOAL_POS[state[i][j]]\n",
    "                distance += abs(x - i) + abs(y - j)\n",
    "    return distance\n",
    "\n",
    "def Euclidean_heuristic(state):\n",
    "    distance = 0\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if state[i][j] != 0:\n",
    "                x, y = GOAL_POS[state[i][j]]\n",
    "                distance += math.sqrt((x - i)**2 + (y - j)**2)\n",
    "    return distance\n",
    "\n",
    "def Max_heuristic(state):\n",
    "    manhattan_distance = 0\n",
    "    misplaced_tiles = 0\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if state[i][j] != 0:\n",
    "                x, y = GOAL_POS[state[i][j]]\n",
    "                manhattan_distance += abs(x - i) + abs(y - j)\n",
    "                if (i, j) != (x, y):\n",
    "                    misplaced_tiles += 1\n",
    "    return max(manhattan_distance, misplaced_tiles)\n",
    "\n",
    "def Linear_Conflict_Heuristic(state):\n",
    "    distance = 0\n",
    "    row_conflicts = [0]*3\n",
    "    column_conflicts = [0]*3\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if state[i][j] != 0:\n",
    "                # Calculate the Manhattan distance\n",
    "                x, y = GOAL_POS[state[i][j]]\n",
    "                distance += abs(x - i) + abs(y - j)\n",
    "\n",
    "                # Check for linear conflicts\n",
    "                if state[i][j] in goal_row_order[i]:\n",
    "                    for k in range(j+1, 3):\n",
    "                        if state[i][k] in goal_row_order[i] and state[i][j] > state[i][k]:\n",
    "                            row_conflicts[i] += 1\n",
    "                if state[j][i] in goal_column_order[i]:\n",
    "                    for k in range(j+1, 3):\n",
    "                        if state[k][i] in goal_column_order[i] and state[j][i] > state[k][i]:\n",
    "                            column_conflicts[i] += 1\n",
    "    linear_conflicts = sum(row_conflicts) + sum(column_conflicts)\n",
    "    return distance + 2*linear_conflicts\n",
    "\n",
    "def default():\n",
    "    print(\"Invalid choice. Please try again.\")\n",
    "\n",
    "switch = {\n",
    "    \"1\": Manhattan_heuristic,\n",
    "    \"2\": Euclidean_heuristic,\n",
    "    \"3\": Max_heuristic,\n",
    "    \"4\": Linear_Conflict_Heuristic,\n",
    "}\n",
    "\n",
    "#...more code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "\n",
    "    # Create a priority queue for the frontier\n",
    "    frontier = PriorityQueue()\n",
    "\n",
    "    # Create a graph to store the state space\n",
    "    G = nx.Graph()\n",
    "\n",
    "    print(\"Please select a heuristic:\")\n",
    "    print(\"1. Manhattan\")\n",
    "    print(\"2. Euclidean\")\n",
    "    print(\"3. Max\")\n",
    "    print(\"4. Linear Conflict\")\n",
    "    print(\"5. Exit\")\n",
    "\n",
    "    choice = input(\"Enter your choice: \")\n",
    "\n",
    "    if choice == \"5\":\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    else:\n",
    "\n",
    "        heuristic_function = switch.get(choice, default)\n",
    "        cost = search(INITIAL_STATE, 0, heuristic_function)\n",
    "\n",
    "        #...more code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Implementation of Logic problems in prolog (snippets from the code)\n",
    "### 1. The Farmer, Wolf, Goat, Cabbage problem\n",
    "The highlighs can be summarized as follows:\n",
    "- The code searches the solution using the _path/3_ predicate which recibes a state and, _if state == goal_, returns the solution. Otherwise, it keeps looking for states til completion.\n",
    "- To change between states, different move functions are implemented, one for each possible scenario: farmer takes wolf, farmer takes goat, farmer takes cabbage, farmer takes self. This has been done through the creation of _move/2_ predicates which will attempt to get to the goal. If a dead point is reached, then it backtracks to the previous position and tries again. A _not(member_queue/2)_ predicate has been implemented as a predicate to avoid checking over a previously checked state.\n",
    "- The constrains of the problem are defined through the _unsafe/1_ and the _opp/2_ predicates.\n",
    "- Note that this code uses the adts.pl file provided as a code resource for George Luger's book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%...more code\n",
    "\n",
    "path(Goal,Goal,Been_queue) :-\n",
    "    write('Solution Path Is:' ), nl,\n",
    "    print_queue(Been_queue).\n",
    "\n",
    "path(State,Goal,Been_queue) :-\n",
    "    move(State,Next_state),\n",
    "    not(member_queue(Next_state,Been_queue)),\n",
    "    add_to_queue(Next_state, Been_queue, New_been_queue),\n",
    "    path(Next_state,Goal,New_been_queue),!.\n",
    "\n",
    "move(state(X,X,G,C), state(Y,Y,G,C))\n",
    "              :- opp(X,Y), not(unsafe(state(Y,Y,G,C))),\n",
    "                 writelist(['try farmer takes wolf',Y,Y,G,C]).\n",
    "\n",
    "%...more moves\n",
    "\n",
    "unsafe(state(X,Y,Y,C)) :- opp(X,Y).\n",
    "\n",
    "%...\n",
    "\n",
    "opp(e,w).\n",
    "\n",
    "%...print the solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The cannibals and missionaries problem\n",
    "\n",
    "An important note here is that it was attempted to reach a solution through the sole modification of the F_W_G_C problem though the difficulty of the task forced to start over the implementation. Thereby, the constrains were defined explicitly in a way that only two move predicates were required instead of one for each possible river crossing state. The most important highlights are:\n",
    "- A _valid/1_ predicate checks that both sides of the river have enough missionaries to avoid being eaten by the cannibals.\n",
    "- The _move/3_ predicates work for either moving from coast 0 to 1 or 1 to 0 (thus resulting in only two move possibilities) for which the passengers of the trip are limited to the list [DM, DC] as part of list containing all possible combinations of missionaries and cannibals.\n",
    "- the _solve/4_ predicate starts the _depthfirst/6_ predicate which goes through the nodes checking wheter or not the current node equals the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%...more code\n",
    "\n",
    "% Valid state\n",
    "valid(state(M, C, _)) :-\n",
    "    M >= 0, C >= 0, M =< 3, C =< 3,\n",
    "    (M >= C ; M = 0),\n",
    "    M2 is 3 - M, C2 is 3 - C,\n",
    "    (M2 >= C2 ; M2 = 0).\n",
    "\n",
    "% Possible moves\n",
    "move(state(M, C, B), state(M2, C2, B2), Move) :-\n",
    "    B = 0, B2 is 1, % Move from original side to other side\n",
    "    member([DM, DC], [[0, 1], [0, 2], [1, 0], [1, 1], [2, 0]]), % Possible combinations of missionaries and cannibals to move\n",
    "    M2 is M - DM, C2 is C - DC, valid(state(M2, C2, B2)),\n",
    "    Move = move(DM, DC, B2).\n",
    "\n",
    "move(state(M, C, B), state(M2, C2, B2), Move) :-\n",
    "    B = 1, B2 is 0, % Move from other side to original side\n",
    "    member([DM, DC], [[0, 1], [0, 2], [1, 0], [1, 1], [2, 0]]), % Possible combinations of missionaries and cannibals to move\n",
    "    M2 is M + DM, C2 is C + DC, valid(state(M2, C2, B2)),\n",
    "    Move = move(DM, DC, B2).\n",
    "\n",
    "% Solve the problem\n",
    "solve(Node, Path, Moves, Goal) :-\n",
    "    depthfirst(Node, Path, Moves, [Node], [], Goal).\n",
    "\n",
    "depthfirst(Node, [Node], [], _, _, Goal) :-\n",
    "    goal(Node, Goal).\n",
    "\n",
    "%...more code"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
